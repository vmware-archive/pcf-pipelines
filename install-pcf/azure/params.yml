##############################################
### Concourse Objects
##############################################
git_private_key:

##############################################
### PCF Object Params
##############################################
opsman_major_minor_version: '1\.12\..*' # Reqd
ert_major_minor_version: '1\.12\..*' # Reqd

# Pivent Download token
pivnet_token: CHANGEME

# ERT Domain Name
pcf_ert_domain: CHANGEME # This is the domain you will access ERT with
system_domain: CHANGEME # This is usually sys.${pcf_ert_domain}
apps_domain: CHANGEME # This is usually cfapps.${pcf_ert_domain}
pcf_ssh_key_pub: CHANGEME
pcf_ssh_key_priv: |
  CHANGEME

# Opsman Settings
opsman_domain_or_ip_address: CHANGEME # This should be your pcf_ert_domain with "opsman." as a prefix
pcf_opsman_admin_username: CHANGEME
pcf_opsman_admin_password: CHANGEME

haproxy_forward_tls: enable # If enabled HAProxy will forward all requests to the router over TLS (enable|disable)
haproxy_backend_ca:         # HAProxy will use the CA provided to verify the certificates provided by the router.

# An ordered, colon-delimited list of Golang supported TLS cipher suites in OpenSSL format.
# Operators should verify that these are supported by any clients or downstream components that will initiate TLS handshakes with the Router/HAProxy.
router_tls_ciphers:         # The recommended setting is "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384".
haproxy_tls_ciphers:        # The recommended setting is "DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384".

# ERT Cert & Key, if the string is blank, then the pipeline will auto generate certs
pcf_ert_ssl_cert:
pcf_ert_ssl_key:

trusted_certificates: # Trusted certificates to be deployed along with all VM's provisioned by BOSH

# SAML Service Credential provider Cert and Key, if the string is blank, then the pipeline will auto generate certs
pcf_ert_saml_cert:
pcf_ert_saml_key:

##############################################
### IaaS Specific Params
##############################################
# Wipe Arg(s) anything other than wipe bypasses the wipe-env job
arg_wipe: wipe

# The storage account and container that will be used for your terraform state
terraform_azure_account_name: CHANGEME
terraform_azure_access_key: CHANGEME
terraform_statefile_container: CHANGEME

### azure ###
# IF the azure_access_name is empty "", ERT will use internal storage. If you want ERT to use Azure blob store, provide a valid azure_account_name and azure_account_key values.
azure_account_name:

# REQD if Azure blob storage is used as external storage by ERT, which is determined by azure_access_name being not null. This setting is used to specify the container where the buildpacks will be stored. It is similar to the S3 bucket in AWS.
azure_buildpacks_container:

# REQD if Azure blob storage is used as external storage by ERT, which is determined by azure_access_name being not null. This setting is used to specify the container where the droplets will be stored. It is similar to the S3 bucket in AWS.
azure_droplets_container:

# REQD if Azure blob storage is used as external storage by ERT, which is determined by azure_access_name being not null. This setting is used to specify the container where the packages will be stored. It is similar to the S3 bucket in AWS.
azure_packages_container:

# REQD if Azure blob storage is used as external storage by ERT, which is determined by azure_access_name being not null. This setting is used to specify the container where the resources will be stored. It is similar to the S3 bucket in AWS.
azure_resources_container:

azure_multi_resgroup_network:
azure_multi_resgroup_pcf:
azure_multi_resgroup_infra_subnet_name:
azure_multi_resgroup_infra_vnet_name:

azure_pcf_terraform_template: c0-azure-base # 'Template' for pipeline to determine Terrafrom & Opsman JSON config
azure_region:
azure_service_principal_id:
azure_service_principal_password:
azure_subscription_id:
azure_tenant_id:
azure_terraform_prefix:
azure_terraform_subnet_dynamic_services_cidr: "192.168.12.0/22"
azure_terraform_subnet_dynamic_services_dns: "168.63.129.16,8.8.8.8"
azure_terraform_subnet_dynamic_services_gateway: "192.168.12.1"
azure_terraform_subnet_dynamic_services_reserved: "192.168.12.1-192.168.12.9"
azure_terraform_subnet_ert_cidr: "192.168.4.0/22"
azure_terraform_subnet_ert_dns: "168.63.129.16,8.8.8.8"
azure_terraform_subnet_ert_gateway: "192.168.4.1"
azure_terraform_subnet_ert_reserved: "192.168.4.1-192.168.4.9"
azure_terraform_subnet_infra_cidr: "192.168.0.0/26"
azure_terraform_subnet_infra_dns: "168.63.129.16,8.8.8.8"
azure_terraform_subnet_infra_gateway: "192.168.0.1"
azure_terraform_subnet_infra_reserved: "192.168.0.1-192.168.0.9"
azure_terraform_subnet_services1_cidr: "192.168.8.0/22"
azure_terraform_subnet_services1_dns: "168.63.129.16,8.8.8.8"
azure_terraform_subnet_services1_gateway: "192.168.8.1"
azure_terraform_subnet_services1_reserved: "192.168.8.1-192.168.8.9"
azure_terraform_vnet_cidr: "192.168.0.0/20"

# azure_vm_admin value should match with userid used to create the certs pcf_ssh_key_pub. The userid will appear towards the end of the pub key
azure_vm_admin: CHANGEME
azure_vm_password:

mysql_monitor_recipient_email:  # Email address for sending mysql monitor notifications
mysql_backups: disable   # Whether to enable MySQL backups. (disable|s3|scp)

#SCP backup config params (leave empty values if you're not using scp
mysql_backups_scp_server:
mysql_backups_scp_port:
mysql_backups_scp_user:
mysql_backups_scp_key:
mysql_backups_scp_destination:
mysql_backups_scp_cron_schedule:

#S3 backup config params (leave empty values if you're not using s3)
mysql_backups_s3_endpoint_url:
mysql_backups_s3_bucket_name:
mysql_backups_s3_bucket_path:
mysql_backups_s3_access_key_id:
mysql_backups_s3_secret_access_key:
mysql_backups_s3_cron_schedule:

## These resources can take any parameter made available in
## the ops manager API ( https://your-ops-man/docs#configuring-resources-for-a-job )
nats_instances: 2
nfs_server_instances: 1
mysql_proxy_instances: 1
mysql_instances: 1
backup_prepare_instances: 0
uaa_instances: 2
cloud_controller_instances: 2
ha_proxy_instances: 1
mysql_monitor_instances: 0
clock_global_instances: 1
cloud_controller_worker_instances: 2
consul_server_instances: 3
diego_database_instances: 3
router_instances: 3
diego_brain_instances: 3
diego_cell_instances: 3
loggregator_traffic_controller_instances: 3
syslog_adapter_instances: 3
doppler_instances: 3
tcp_router_instances: 0

deployment_network_name: "ert"
enable_security_event_logging: true
syslog_host:
syslog_port:
syslog_protocol:
syslog_drain_buffer_size:
company_name: CHANGEME
authentication_mode: CHANGEME
loggregator_endpoint_port:
disable_http_proxy:
tcp_routing: disable
tcp_routing_ports:
route_services: enable
ignore_ssl_cert_verification: true
smtp_from:
smtp_address:
smtp_port:
smtp_user:
smtp_pwd:
smtp_auth_mechanism:
security_acknowledgement: CHANGEME # Change to 'X'
default_quota_memory_limit_mb: 10240
default_quota_max_number_services: 1000
ha_proxy_ips: CHANGEME
skip_cert_verify: true
disable_insecure_cookies: false
router_static_ips:
router_request_timeout_in_seconds: 900
garden_network_pool_cidr: 10.254.0.0/22 # Only change this if you need to avoid address collision with a third-party service on the same subnet.
garden_network_mtu: 1454
allow_app_ssh_access: false
tcp_router_static_ips:
ssh_static_ips:
ha_proxy_lb_name: CHANGEME
