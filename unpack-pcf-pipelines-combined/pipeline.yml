resources:
- name: pcf-ops-manager
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "ops-manager/ops-manager-(.*).tar"
    unpack: true

- name: elastic-runtime
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "elastic-runtime/elastic-runtime-(.*).tar"
    unpack: true

- name: czero-cflinuxfs2
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "czero-cflinuxfs2/czero-cflinuxfs2-(.*)-.*.tar"

- name: pcf-pipelines-combined
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "pcf-pipelines-combined/pcf-pipelines-combined-(.*).tar.gpg"

- name: stemcells
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "stemcells/bosh-stemcell-(.*)-.*.tgz"

- name: pcf-pipelines-tarball
  type: s3
  source:
    access_key_id: {{s3_access_key_id}}
    secret_access_key: {{s3_secret_access_key}}
    endpoint: {{s3_endpoint}}
    bucket: {{s3_bucket}}
    regexp: "pcf-pipelines/pcf-pipelines-(.*).tgz"

jobs:
- name: unpack-tarball
  plan:
  - get: pcf-pipelines-combined
    trigger: true
  - task: unpack-tarball
    config:
      platform: linux
      image_resource:
        type: s3
        source:
          access_key_id: {{s3_access_key_id}}
          secret_access_key: {{s3_secret_access_key}}
          endpoint: {{s3_endpoint}}
          bucket: {{s3_bucket}}
          regexp: "czero-cflinuxfs2/czero-cflinuxfs2-(.*)-.*.tar"
        params:
          unpack: true
      inputs:
      - name: pcf-pipelines-combined
      outputs:
      - name: pcf-pipelines-separated
      params:
        GPG_PRIVATE_KEY: {{gpg_private_key_contents}}
      run:
        path: bash
        args:
        - -c
        - |
          set -eu
          set -o pipefail

          echo -n "Importing GPG private key..."
          echo "$GPG_PRIVATE_KEY" | gpg --import 2>/dev/null
          echo "done"

          echo ""
          echo "Extracting encrypted tarball..."
          gpg --decrypt pcf-pipelines-combined/*.tar.gpg | tar xv -C pcf-pipelines-separated

          echo ""
          echo "Verifying SHA of extracted files..."
          pushd pcf-pipelines-separated 1>/dev/null
            shasum -c MANIFEST.MF
          popd 1>/dev/null
  - aggregate:
    - put: pcf-ops-manager
      params:
        file: pcf-pipelines-separated/ops-manager*
    - put: elastic-runtime
      params:
        file: pcf-pipelines-separated/elastic-runtime*
    - put: czero-cflinuxfs2
      params:
        file: pcf-pipelines-separated/czero-cflinuxfs2*
    - put: stemcells
      params:
        file: pcf-pipelines-separated/bosh-stemcell*
    - put: pcf-pipelines-tarball
      params:
        file: pcf-pipelines-separated/pcf-pipelines*

- name: set-install-pcf-pipeline
  plan:
  - get: pcf-pipelines-tarball
    passed: [unpack-tarball]
  - task: unpack-pcf-pipelines
    config:
      platform: linux
      image_resource:
        type: s3
        source:
          access_key_id: {{s3_access_key_id}}
          secret_access_key: {{s3_secret_access_key}}
          endpoint: {{s3_endpoint}}
          bucket: {{s3_bucket}}
          regexp: "czero-cflinuxfs2/czero-cflinuxfs2-(.*)-.*.tar"
        params:
          unpack: true
      inputs:
      - name: pcf-pipelines-tarball
      outputs:
      - name: pcf-pipelines
      run:
       path: bash
       args: ["-c", "tar -C pcf-pipelines -xvf pcf-pipelines-tarball/*.tgz"]
  - task: set-pipeline
    config:
      platform: linux
      image_resource:
        type: s3
        source:
          access_key_id: {{s3_access_key_id}}
          secret_access_key: {{s3_secret_access_key}}
          endpoint: {{s3_endpoint}}
          bucket: {{s3_bucket}}
          regexp: "czero-cflinuxfs2/czero-cflinuxfs2-(.*)-.*.tar"
        params:
          unpack: true
      inputs:
      - name: pcf-pipelines
      params:
        PIPELINE_PARAMS: {{install_pcf_pipeline_params}}
        PIPELINE_NAME: {{install_pcf_pipeline_name}}
        PIPELINE_PATH: pcf-pipelines/install-pcf/vsphere/pipeline.yml
        ATC_EXTERNAL_URL: {{atc_external_url}}
        ATC_BASIC_AUTH_USERNAME: {{atc_basic_auth_username}}
        ATC_BASIC_AUTH_PASSWORD: {{atc_basic_auth_password}}
        ATC_TEAM_NAME: {{atc_team_name}}
      run:
        path: bash
        args:
        - -c
        - |
          curl \
            --insecure \
            --output fly \
            "${ATC_EXTERNAL_URL}/api/v1/cli?arch=amd64&platform=linux"

          chmod +x fly

          ./fly --target self login \
            --insecure \
            --concourse-url "${ATC_EXTERNAL_URL}" \
            --username "${ATC_BASIC_AUTH_USERNAME}" \
            --password "${ATC_BASIC_AUTH_PASSWORD}" \
            --team-name "${ATC_TEAM_NAME}"

          IFS=$'\n'
          for line in $PIPELINE_PARAMS; do
            echo "$line" >> params.yml
          done

          ./fly --target self set-pipeline \
            --non-interactive \
            --pipeline "${PIPELINE_NAME}" \
            --config "${PIPELINE_PATH}" \
            --load-vars-from params.yml
